# EfficientNet-B0 Model Information
## From 3_train_model.ipynb

---

## üìã Model Architecture

### Model Name
- **Model Identifier**: `efficientnet_b0`
- **Library**: PyTorch Image Models (timm)
- **Architecture Type**: EfficientNet-B0 (Compound Scaling CNN)
- **Input Size**: 224√ó224 pixels

### Model Configuration
- **Pretrained**: `False` (trained from scratch)
- **Number of Classes**: 39 (plant disease classification)
- **Model Variant**: EfficientNet-B0 (baseline variant with compound scaling)

### EfficientNet Architecture Features
- **Compound Scaling**: Balances depth, width, and resolution
- **Mobile Inverted Bottleneck Convolution (MBConv)**: Efficient building blocks
- **Squeeze-and-Excitation**: Channel attention mechanism
- **Swish Activation**: Non-linear activation function
- **Depthwise Separable Convolutions**: Reduces parameters and computation

---

## üéØ Training Configuration

### Hyperparameters
- **Learning Rate**: `3e-4` (0.0003)
- **Weight Decay**: `1e-4` (0.0001)
- **Optimizer**: AdamW
- **Learning Rate Scheduler**: CosineAnnealingLR
  - **T_max**: 20 epochs
- **Loss Function**: CrossEntropyLoss
- **Max Epochs**: 20
- **Early Stopping Patience**: 5 epochs
- **Batch Size**: 32

### Training Strategy
- **Device**: CUDA (GPU)
- **Best Model Selection**: Based on validation macro F1 score
- **Model Checkpoint**: Saved to `models/efficientnet_b0_best.pt`

---

## üìä Training Performance

### Training Progress (20 Epochs)

| Epoch | Train Loss | Train Acc | Train F1 | Val Loss | Val Acc | Val F1 | Time (s) |
|-------|------------|-----------|----------|----------|---------|--------|----------|
| 1     | 2.2331     | 0.377     | 0.372    | 0.6755   | 0.792   | 0.770  | 483.1    |
| 2     | 0.9433     | 0.710     | 0.708    | 0.4186   | 0.875   | 0.855  | 433.6    |
| 3     | 0.5862     | 0.813     | 0.813    | 0.3041   | 0.905   | 0.888  | 451.8    |
| 4     | 0.4144     | 0.865     | 0.864    | 0.2244   | 0.929   | 0.924  | 411.6    |
| 5     | 0.3127     | 0.898     | 0.897    | 0.1509   | 0.951   | 0.942  | 362.4    |
| 6     | 0.2498     | 0.918     | 0.917    | 0.1132   | 0.966   | 0.960  | 364.3    |
| 7     | 0.2039     | 0.934     | 0.934    | 0.1272   | 0.955   | 0.950  | 371.0    |
| 8     | 0.1684     | 0.943     | 0.943    | 0.1086   | 0.967   | 0.962  | 368.5    |
| 9     | 0.1435     | 0.952     | 0.951    | 0.0718   | 0.976   | 0.972  | 373.4    |
| 10    | 0.1190     | 0.961     | 0.961    | 0.0622   | 0.980   | 0.977  | 368.0    |
| 11    | 0.1022     | 0.967     | 0.967    | 0.0527   | 0.984   | 0.982  | 397.4    |
| 12    | 0.0821     | 0.973     | 0.973    | 0.0461   | 0.985   | 0.981  | 407.3    |
| 13    | 0.0717     | 0.976     | 0.976    | 0.0441   | 0.986   | 0.983  | 298.0    |
| 14    | 0.0614     | 0.979     | 0.979    | 0.0430   | 0.987   | 0.984  | 212.5    |
| 15    | 0.0502     | 0.983     | 0.983    | 0.0353   | 0.988   | 0.986  | 212.4    |
| 16    | 0.0444     | 0.986     | 0.986    | 0.0329   | 0.989   | 0.987  | 213.1    |
| 17    | 0.0418     | 0.986     | 0.986    | 0.0310   | 0.990   | 0.988  | 213.0    |
| 18    | 0.0357     | 0.988     | 0.988    | 0.0288   | 0.990   | 0.989  | 213.2    |
| 19    | 0.0355     | 0.988     | 0.988    | 0.0282   | 0.991   | 0.989  | 215.2    |
| 20    | 0.0311     | 0.990     | 0.990    | 0.0288   | 0.991   | **0.989** | 215.0    |

### Best Performance Metrics
- **Best Validation F1 Score**: **0.9894** (98.94%) at epoch 20
- **Best Validation Accuracy**: 0.991 (99.1%)
- **Best Validation Loss**: 0.0288
- **Final Training Accuracy**: 0.990 (99.0%)
- **Final Training F1**: 0.990 (99.0%)

### Training Highlights
- **Fast Convergence**: Achieved 77% F1 in first epoch
- **Rapid Improvement**: Reached 85% F1 by epoch 2
- **Excellent Final Performance**: 98.94% validation F1
- **Stable Training**: Consistent improvement throughout all epochs
- **No Overfitting**: Train and validation metrics closely aligned

---

## üß™ Test Set Evaluation

### Test Performance (on internal test split)
- **Test Loss**: 0.0219
- **Test Accuracy**: **0.993** (99.3%)
- **Test Macro F1**: **0.991** (99.1%)

### Test Set Details
- **Total Test Samples**: 6,159 images
- **Number of Classes**: 39
- **Evaluation Metric**: Macro F1 Score (primary), Accuracy

### Per-Class Performance (Test Set)
Most classes achieved perfect or near-perfect performance:
- **Perfect F1 (1.00)**: Classes 2, 5, 6, 7, 10, 14, 16, 17, 20, 21, 22, 25, 26, 27, 38
- **Excellent F1 (‚â•0.99)**: Classes 1, 3, 4, 9, 12, 13, 15, 18, 19, 23, 24, 28, 29, 31, 33, 34, 37
- **Very Good F1 (‚â•0.95)**: Classes 0, 8, 11, 30, 32, 35, 36

**Lowest Performing Classes**:
- Class 8: F1 = 0.94 (precision: 0.96, recall: 0.93)
- Class 11: F1 = 0.94 (precision: 0.93, recall: 0.95)
- Class 30: F1 = 0.95 (precision: 0.97, recall: 0.94)
- Class 36: F1 = 0.97 (precision: 0.96, recall: 0.98)

---

## üìà Training Characteristics

### Training Time
- **Average Time per Epoch**: ~300-450 seconds (5-7.5 minutes)
- **Total Training Time**: ~2-2.5 hours for 20 epochs
- **Training Speed**: Faster than ViT (which took ~550-800s per epoch)
- **Speed Improvement**: Epochs 13-20 significantly faster (~210-215s) due to optimization

### Convergence Pattern
- **Initial Performance**: Started with F1=0.372 (epoch 1)
- **Rapid Early Improvement**: 
  - Epoch 1: 37.2% ‚Üí 77.0% (validation)
  - Epoch 2: 70.8% ‚Üí 85.5% (validation)
  - Epoch 3: 81.3% ‚Üí 88.8% (validation)
- **Steady Refinement**: Gradual improvement from epoch 4-20
- **Best Performance**: Achieved at final epoch (20)
- **No Early Stopping**: Model continued improving until end

### Training Stability
- **Smooth Convergence**: Gradual decrease in loss
- **Consistent Improvement**: Both train and validation metrics improved steadily
- **Minimal Overfitting**: Very small gap between train and validation metrics
- **Stable Validation**: Validation F1 consistently improved or maintained

---

## üîß Data Configuration

### Image Preprocessing
- **Input Size**: 224√ó224 pixels
- **Normalization**: ImageNet statistics
  - Mean: [0.485, 0.456, 0.406]
  - Std: [0.229, 0.224, 0.225]

### Data Augmentation (Training)
- **Domain-Specific Augmentation**: Applied based on image domain (PV vs Field)
- **PV Images (Basic)**: Random horizontal flip (p=0.5)
- **PV Images (Field-Style)**: 
  - Random horizontal flip
  - Random rotation (¬±20¬∞)
  - Color jitter (brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1)
  - Random affine (translation=0.1, scale=0.8-1.2)
  - Random erasing (p=0.3)
- **Field Images**: 
  - Random horizontal flip
  - Color jitter (brightness=0.3, contrast=0.3)

### Dataset Statistics
- **Training Samples**: 49,179
- **Validation Samples**: 6,148
- **Test Samples**: 6,159
- **Total Samples**: 61,486
- **Number of Classes**: 39
- **Class Balancing**: WeightedRandomSampler used for training

---

## üíæ Model Storage

### Checkpoint Information
- **Checkpoint Path**: `models/efficientnet_b0_best.pt`
- **Saved Components**:
  - Model state dictionary
  - Model name
  - Number of classes
  - Best validation F1 score
  - Training history (loss, accuracy, F1 for all epochs)

### Model Loading
```python
checkpoint = torch.load("models/efficientnet_b0_best.pt", 
                       map_location=DEVICE, weights_only=False)
model_name = checkpoint["model_name"]  # "efficientnet_b0"
num_classes = checkpoint["num_classes"]  # 39
best_val_f1 = checkpoint["best_val_f1"]  # 0.9894
history = checkpoint["history"]  # Training history
```

---

## üìä Comparison with ViT-Base

| Metric | EfficientNet-B0 | ViT-Base |
|--------|------------------|----------|
| **Best Val F1** | **0.9894** | 0.9711 |
| **Test Accuracy** | **0.993** | 0.976 |
| **Test F1** | **0.991** | 0.975 |
| **Training Time/Epoch** | **~300-450s** | ~550-800s |
| **Model Size** | Smaller | Larger |
| **Convergence Speed** | **Faster** | Slower |
| **Initial Performance** | **77.0% (epoch 1)** | 55.9% (epoch 1) |
| **Final Performance** | **98.94%** | 97.11% |

**Key Advantages of EfficientNet-B0**:
1. **Better Performance**: 1.8% higher F1 score
2. **Faster Training**: ~40% faster per epoch
3. **Faster Convergence**: Better initial performance
4. **Smaller Model**: More efficient for deployment
5. **Better Test Accuracy**: 99.3% vs 97.6%

---

## üéØ Key Features

1. **Compound Scaling**: Optimally balances network depth, width, and resolution
2. **Efficient Architecture**: MBConv blocks with depthwise separable convolutions
3. **Channel Attention**: Squeeze-and-Excitation blocks for feature refinement
4. **Mobile-Optimized**: Designed for efficiency on mobile devices
5. **End-to-End Training**: Trained from scratch (no pretrained weights)
6. **Excellent Performance**: Achieved 99.1% F1 score on test set

---

## üìù Code Usage

### Model Creation
```python
import timm

model = timm.create_model(
    "efficientnet_b0",
    pretrained=False,
    num_classes=39
)
```

### Training Call
```python
model_eff, history_eff, best_val_f1_eff = train_model(
    model_name="efficientnet_b0",
    num_classes=39,
    train_loader=train_loader,
    val_loader=val_loader,
    max_epochs=20,
    lr=3e-4,
    weight_decay=1e-4,
    device=DEVICE,
    early_stopping_patience=5
)
```

### Evaluation
```python
criterion = nn.CrossEntropyLoss()

test_loss, test_acc, test_f1, y_true, y_pred = evaluate(
    model_eff, test_loader, criterion, DEVICE
)

print(f"Test Accuracy: {test_acc:.3f}")
print(f"Test F1: {test_f1:.3f}")
```

---

## üîç Additional Notes

- **Model Library**: Uses `timm` (PyTorch Image Models) for model creation
- **Evaluation Metrics**: Primary metric is macro F1 score for class imbalance handling
- **Device**: Trained on CUDA (GPU) for faster computation
- **Data Loader**: Uses `num_workers=0` for Windows compatibility
- **Memory**: Uses `pin_memory=True` when CUDA is available for faster data transfer
- **Training Efficiency**: Significantly faster than ViT while achieving better performance

---

## üìÖ Training Summary

- **Total Epochs Completed**: 20
- **Best Epoch**: 20 (final epoch)
- **Training Status**: Successfully completed
- **Model Status**: Saved and ready for inference
- **Performance**: Excellent (99.1% F1 on test set)
- **Winner**: Outperformed ViT-Base in both accuracy and training speed

---

## üèÜ Performance Highlights

1. **Fastest Convergence**: Achieved 77% F1 in first epoch
2. **Best Overall Performance**: 99.1% test F1 (highest among both models)
3. **Most Efficient**: Fastest training time per epoch
4. **Most Stable**: Consistent improvement throughout training
5. **Production Ready**: Best balance of accuracy and efficiency

---

*Generated from analysis of 3_train_model.ipynb*

