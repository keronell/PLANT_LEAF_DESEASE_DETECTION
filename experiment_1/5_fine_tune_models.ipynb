{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tuning Pre-trained Models on Combined Datasets\n",
        "\n",
        "This notebook implements fine-tuning of pre-trained EfficientNet-B0 and ViT-Base models on a combined dataset that includes:\n",
        "1. **Main Dataset**: Plant_leaf_diseases_dataset_with_augmentation (all 39 classes)\n",
        "2. **Plant_doc Dataset**: Additional training data for overlapping classes\n",
        "3. **FieldPlant Dataset**: Real-world field images for domain adaptation\n",
        "\n",
        "## Fine-Tuning Strategy:\n",
        "- **Lower Learning Rate**: 1e-4 (10x lower than original 3e-4)\n",
        "- **Fewer Epochs**: 5 epochs (vs 20 in original training)\n",
        "- **Layer-wise Learning Rates**: Different rates for early vs later layers\n",
        "- **Evaluation**: Separate validation on all three datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Optimizations for RTX 3070 Super\n",
        "\n",
        "**Optimizations Applied:**\n",
        "1. **Mixed Precision Training (FP16)** - ~1.5-2x speedup, uses less VRAM\n",
        "2. **Increased Batch Size** - 32 â†’ 64 (RTX 3070 Super can handle it with FP16)\n",
        "3. **Path Resolution** - Fixed for experiment_1/ subdirectory\n",
        "4. **Pretrained Models** - Ensures ImageNet pretrained weights are used\n",
        "5. **num_workers=0** - Avoids multiprocessing issues on Windows\n",
        "\n",
        "**Expected Speedup:** 2-3x faster training per epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Mixed Precision (AMP): Enabled\n",
            "torch.compile available (but disabled): True\n",
            "Current working directory: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\experiment_1\n",
            "Base directory: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\n",
            "Metadata directory: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\metadata\n",
            "Models directory: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\models\n"
          ]
        }
      ],
      "source": [
        "# Imports and Setup\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.amp import GradScaler\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import timm\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# Check for mixed precision support\n",
        "USE_AMP = torch.cuda.is_available() and hasattr(torch.cuda, 'amp')\n",
        "print(f\"Mixed Precision (AMP): {'Enabled' if USE_AMP else 'Disabled'}\")\n",
        "\n",
        "# Check PyTorch version for torch.compile (disabled for stability)\n",
        "USE_COMPILE = False  # hasattr(torch, 'compile') and torch.__version__ >= \"2.0.0\"\n",
        "print(f\"torch.compile available (but disabled): {hasattr(torch, 'compile')}\")\n",
        "\n",
        "# Paths - adjusted for notebook location in experiment_1/ subdirectory\n",
        "import os\n",
        "current_dir = Path(os.getcwd())\n",
        "\n",
        "# Check if we're in experiment_1 subdirectory\n",
        "if current_dir.name == \"experiment_1\":\n",
        "    BASE_DIR = current_dir.parent\n",
        "else:\n",
        "    # If running from root PLANT_LEAF_DISEASE_DETECTION, use current directory\n",
        "    BASE_DIR = current_dir\n",
        "\n",
        "METADATA_DIR = BASE_DIR / \"metadata\"\n",
        "LABEL_MAPPING_PATH = METADATA_DIR / \"label_mapping.json\"\n",
        "DATASET_INDEX_PATH = METADATA_DIR / \"dataset_index.json\"\n",
        "DATA_DIR = BASE_DIR / \"data\"\n",
        "PLANT_DOC_DIR = DATA_DIR / \"Plant_doc\"  # Base directory - function will append train/test\n",
        "FIELDPLANT_DIR = DATA_DIR / \"FieldPlant_reformatted\"\n",
        "\n",
        "MODELS_DIR = BASE_DIR / \"models\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Current working directory: {current_dir}\")\n",
        "print(f\"Base directory: {BASE_DIR}\")\n",
        "print(f\"Metadata directory: {METADATA_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Metadata and Create Class Mappings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Main dataset: 39 classes\n",
            "Total samples in dataset_index: 61486\n",
            "Field-poor classes: 39\n"
          ]
        }
      ],
      "source": [
        "# Load main dataset metadata\n",
        "with open(LABEL_MAPPING_PATH, \"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "\n",
        "with open(DATASET_INDEX_PATH, \"r\") as f:\n",
        "    dataset_index = json.load(f)\n",
        "\n",
        "# Create mappings\n",
        "id_to_label = {c[\"id\"]: c[\"canonical_label\"] for c in label_mapping[\"classes\"]}\n",
        "label_to_id = {v: k for k, v in id_to_label.items()}\n",
        "folder_to_label = {}\n",
        "for c in label_mapping[\"classes\"]:\n",
        "    for folder in c.get(\"pv_folders\", []):\n",
        "        folder_to_label[folder] = c[\"canonical_label\"]\n",
        "\n",
        "num_classes = len(label_mapping[\"classes\"])\n",
        "print(f\"Main dataset: {num_classes} classes\")\n",
        "print(f\"Total samples in dataset_index: {len(dataset_index)}\")\n",
        "\n",
        "# Field-poor classes (for augmentations)\n",
        "FIELD_POOR_THRESHOLD = 5\n",
        "field_count_by_class = {\n",
        "    c[\"id\"]: c.get(\"field_count\", 0)\n",
        "    for c in label_mapping[\"classes\"]\n",
        "}\n",
        "field_poor_classes = {\n",
        "    cid for cid, cnt in field_count_by_class.items()\n",
        "    if cnt <= FIELD_POOR_THRESHOLD\n",
        "}\n",
        "print(f\"Field-poor classes: {len(field_poor_classes)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Mappings for Plant_doc and FieldPlant to Main Dataset Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plant_doc mappings: 27 classes\n",
            "FieldPlant mappings: 7 classes\n"
          ]
        }
      ],
      "source": [
        "# Mapping from Plant_doc folder names to canonical labels\n",
        "# Based on dataset_classes_diagram.txt analysis\n",
        "plant_doc_to_canonical = {\n",
        "    \"Apple_leaf\": \"apple_healthy\",\n",
        "    \"Apple_rust_leaf\": \"apple_cedar_apple_rust\",\n",
        "    \"Apple_Scab_Leaf\": \"apple_apple_scab\",\n",
        "    \"Bell_pepper_leaf\": \"pepper,_bell_healthy\",\n",
        "    \"Bell_pepper_leaf_spot\": \"pepper,_bell_bacterial_spot\",\n",
        "    \"Blueberry_leaf\": \"blueberry_healthy\",\n",
        "    \"Cherry_leaf\": \"cherry_healthy\",\n",
        "    \"Corn_Gray_leaf_spot\": \"corn_cercospora_leaf_spot_gray_leaf_spot\",\n",
        "    \"Corn_leaf_blight\": \"corn_northern_leaf_blight\",\n",
        "    \"Corn_rust_leaf\": \"corn_common_rust\",\n",
        "    \"grape_leaf\": \"grape_healthy\",\n",
        "    \"grape_leaf_black_rot\": \"grape_black_rot\",\n",
        "    \"Peach_leaf\": \"peach_healthy\",\n",
        "    \"Potato_leaf_early_blight\": \"potato_early_blight\",\n",
        "    \"Potato_leaf_late_blight\": \"potato_late_blight\",\n",
        "    \"Raspberry_leaf\": \"raspberry_healthy\",\n",
        "    \"Soyabean_leaf\": \"soybean_healthy\",\n",
        "    \"Squash_Powdery_mildew_leaf\": \"squash_powdery_mildew\",\n",
        "    \"Strawberry_leaf\": \"strawberry_healthy\",\n",
        "    \"Tomato_Early_blight_leaf\": \"tomato_early_blight\",\n",
        "    \"Tomato_leaf\": \"tomato_healthy\",\n",
        "    \"Tomato_leaf_bacterial_spot\": \"tomato_bacterial_spot\",\n",
        "    \"Tomato_leaf_late_blight\": \"tomato_late_blight\",\n",
        "    \"Tomato_leaf_mosaic_virus\": \"tomato_tomato_mosaic_virus\",\n",
        "    \"Tomato_leaf_yellow_virus\": \"tomato_tomato_yellow_leaf_curl_virus\",\n",
        "    \"Tomato_mold_leaf\": \"tomato_leaf_mold\",\n",
        "    \"Tomato_Septoria_leaf_spot\": \"tomato_septoria_leaf_spot\",\n",
        "}\n",
        "\n",
        "# Mapping from FieldPlant folder names to canonical labels\n",
        "fieldplant_to_canonical = {\n",
        "    \"Corn___Gray_leaf_spot\": \"corn_cercospora_leaf_spot_gray_leaf_spot\",\n",
        "    \"Corn___rust_leaf\": \"corn_common_rust\",\n",
        "    \"Corn___leaf_blight\": \"corn_northern_leaf_blight\",\n",
        "    \"Corn___healthy\": \"corn_healthy\",\n",
        "    \"Tomato___healthy\": \"tomato_healthy\",\n",
        "    \"Tomato___leaf_mosaic_virus\": \"tomato_tomato_mosaic_virus\",\n",
        "    \"Tomato___leaf_yellow_virus\": \"tomato_tomato_yellow_leaf_curl_virus\",\n",
        "    # Add more mappings as needed based on FieldPlant structure\n",
        "}\n",
        "\n",
        "print(f\"Plant_doc mappings: {len(plant_doc_to_canonical)} classes\")\n",
        "print(f\"FieldPlant mappings: {len(fieldplant_to_canonical)} classes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define Data Loading Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loading functions defined.\n"
          ]
        }
      ],
      "source": [
        "def load_plant_doc_data(data_dir, split=\"train\"):\n",
        "    \"\"\"Load Plant_doc dataset entries and map to main dataset class IDs.\"\"\"\n",
        "    entries = []\n",
        "    split_dir = data_dir / split\n",
        "    \n",
        "    if not split_dir.exists():\n",
        "        print(f\"Warning: {split_dir} does not exist!\")\n",
        "        return entries\n",
        "    \n",
        "    for folder in split_dir.iterdir():\n",
        "        if not folder.is_dir():\n",
        "            continue\n",
        "        \n",
        "        canonical = plant_doc_to_canonical.get(folder.name)\n",
        "        if canonical is None:\n",
        "            continue\n",
        "        \n",
        "        if canonical not in label_to_id:\n",
        "            continue\n",
        "        \n",
        "        class_id = label_to_id[canonical]\n",
        "        \n",
        "        # Get all images in folder\n",
        "        image_files = list(folder.glob(\"*.jpg\")) + list(folder.glob(\"*.JPG\"))\n",
        "        for img_path in image_files:\n",
        "            entries.append({\n",
        "                \"path\": str(img_path),\n",
        "                \"class_id\": class_id,\n",
        "                \"dataset\": \"plant_doc\",\n",
        "                \"domain\": \"pv\",\n",
        "                \"split\": split\n",
        "            })\n",
        "    \n",
        "    return entries\n",
        "\n",
        "def load_fieldplant_data(data_dir):\n",
        "    \"\"\"Load FieldPlant dataset entries and map to main dataset class IDs.\"\"\"\n",
        "    entries = []\n",
        "    \n",
        "    if not data_dir.exists():\n",
        "        return entries\n",
        "    \n",
        "    for folder in data_dir.iterdir():\n",
        "        if not folder.is_dir():\n",
        "            continue\n",
        "        \n",
        "        canonical = fieldplant_to_canonical.get(folder.name)\n",
        "        if canonical is None:\n",
        "            continue\n",
        "        \n",
        "        if canonical not in label_to_id:\n",
        "            continue\n",
        "        \n",
        "        class_id = label_to_id[canonical]\n",
        "        \n",
        "        # Get all images in folder\n",
        "        image_files = list(folder.glob(\"*.jpg\")) + list(folder.glob(\"*.JPG\"))\n",
        "        for img_path in image_files:\n",
        "            entries.append({\n",
        "                \"path\": str(img_path),\n",
        "                \"class_id\": class_id,\n",
        "                \"dataset\": \"fieldplant\",\n",
        "                \"domain\": \"field\",\n",
        "                \"split\": \"train\"  # FieldPlant doesn't have split, use all as train\n",
        "            })\n",
        "    \n",
        "    return entries\n",
        "\n",
        "print(\"Data loading functions defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Load and Combine All Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Main dataset training samples: 49179\n",
            "Plant_doc training samples: 5336\n",
            "FieldPlant training samples: 4640\n",
            "\n",
            "Total combined training samples: 59155\n",
            "\n",
            "Training samples by dataset:\n",
            "  fieldplant: 4640\n",
            "  main: 49179\n",
            "  plant_doc: 5336\n",
            "\n",
            "Class distribution (top 10):\n",
            "  Class 38 (tomato_tomato_yellow_leaf_curl_virus): 4961 samples\n",
            "  Class 11 (corn_northern_leaf_blight): 4468 samples\n",
            "  Class 16 (orange_haunglongbing_citrus_greening): 4405 samples\n",
            "  Class 25 (soybean_healthy): 4186 samples\n",
            "  Class 31 (tomato_healthy): 1918 samples\n",
            "  Class 29 (tomato_bacterial_spot): 1903 samples\n",
            "  Class 17 (peach_bacterial_spot): 1837 samples\n",
            "  Class 32 (tomato_late_blight): 1729 samples\n",
            "  Class 26 (squash_powdery_mildew): 1716 samples\n",
            "  Class 34 (tomato_septoria_leaf_spot): 1706 samples\n"
          ]
        }
      ],
      "source": [
        "# Load main dataset training data\n",
        "train_entries_main = [e for e in dataset_index if e[\"split\"] == \"train\"]\n",
        "print(f\"Main dataset training samples: {len(train_entries_main)}\")\n",
        "\n",
        "# Load Plant_doc training data\n",
        "train_entries_plant_doc = load_plant_doc_data(PLANT_DOC_DIR, split=\"train\")\n",
        "print(f\"Plant_doc training samples: {len(train_entries_plant_doc)}\")\n",
        "\n",
        "# Load FieldPlant training data\n",
        "train_entries_fieldplant = load_fieldplant_data(FIELDPLANT_DIR)\n",
        "print(f\"FieldPlant training samples: {len(train_entries_fieldplant)}\")\n",
        "\n",
        "# Combine all training data\n",
        "all_train_entries = train_entries_main + train_entries_plant_doc + train_entries_fieldplant\n",
        "print(f\"\\nTotal combined training samples: {len(all_train_entries)}\")\n",
        "\n",
        "# Show distribution by dataset\n",
        "dataset_counts = Counter(e.get(\"dataset\", \"main\") for e in all_train_entries)\n",
        "print(\"\\nTraining samples by dataset:\")\n",
        "for dataset, count in sorted(dataset_counts.items()):\n",
        "    print(f\"  {dataset}: {count}\")\n",
        "\n",
        "# Show class distribution\n",
        "print(\"\\nClass distribution (top 10):\")\n",
        "class_counts = Counter(e[\"class_id\"] for e in all_train_entries)\n",
        "for class_id, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    class_name = id_to_label[class_id]\n",
        "    print(f\"  Class {class_id} ({class_name}): {count} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Validation Sets from All Three Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Main dataset validation samples: 6148\n",
            "Plant_doc validation samples: 504\n",
            "FieldPlant validation samples: 928\n",
            "FieldPlant training samples (after split): 3712\n"
          ]
        }
      ],
      "source": [
        "# Main dataset validation\n",
        "val_entries_main = [e for e in dataset_index if e[\"split\"] == \"val\"]\n",
        "print(f\"Main dataset validation samples: {len(val_entries_main)}\")\n",
        "\n",
        "# Plant_doc validation (use test set)\n",
        "val_entries_plant_doc = load_plant_doc_data(PLANT_DOC_DIR, split=\"test\")\n",
        "print(f\"Plant_doc validation samples: {len(val_entries_plant_doc)}\")\n",
        "\n",
        "# FieldPlant validation (use 20% of data)\n",
        "val_entries_fieldplant_all = load_fieldplant_data(FIELDPLANT_DIR)\n",
        "np.random.seed(42)\n",
        "if len(val_entries_fieldplant_all) > 0:\n",
        "    indices = np.arange(len(val_entries_fieldplant_all))\n",
        "    np.random.shuffle(indices)\n",
        "    val_size = int(len(val_entries_fieldplant_all) * 0.2)\n",
        "    val_entries_fieldplant = [val_entries_fieldplant_all[i] for i in indices[:val_size]]\n",
        "    # Remove validation samples from training\n",
        "    train_entries_fieldplant = [val_entries_fieldplant_all[i] for i in indices[val_size:]]\n",
        "    # Update training entries\n",
        "    all_train_entries = train_entries_main + train_entries_plant_doc + train_entries_fieldplant\n",
        "    print(f\"FieldPlant validation samples: {len(val_entries_fieldplant)}\")\n",
        "    print(f\"FieldPlant training samples (after split): {len(train_entries_fieldplant)}\")\n",
        "else:\n",
        "    val_entries_fieldplant = []\n",
        "    print(\"FieldPlant validation samples: 0\")\n",
        "\n",
        "# Store separately for per-dataset evaluation\n",
        "validation_sets = {\n",
        "    \"main\": val_entries_main,\n",
        "    \"plant_doc\": val_entries_plant_doc,\n",
        "    \"fieldplant\": val_entries_fieldplant\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Define Dataset Class and Transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Transforms (same as 3_train_model.ipynb)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "IMG_SIZE = 224\n",
        "\n",
        "transform_pv_basic = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "transform_pv_field_style = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(degrees=20),\n",
        "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1),\n",
        "    T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "    T.ToTensor(),\n",
        "    T.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "transform_field = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "transform_eval = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# Dataset class (same as 3_train_model.ipynb)\n",
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, entries, transform_train=True, base_dir=None):\n",
        "        self.entries = entries\n",
        "        self.transform_train = transform_train\n",
        "        self.base_dir = base_dir or BASE_DIR  # Use BASE_DIR from cell 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.entries)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.entries[idx]\n",
        "        img_path = item[\"path\"]\n",
        "        class_id = item[\"class_id\"]\n",
        "        domain = item.get(\"domain\", \"pv\")\n",
        "\n",
        "        # Resolve path relative to BASE_DIR if it's a relative path\n",
        "        if not Path(img_path).is_absolute():\n",
        "            img_path = self.base_dir / img_path\n",
        "        else:\n",
        "            img_path = Path(img_path)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
        "            class_id = 0\n",
        "\n",
        "        if self.transform_train:\n",
        "            if domain == \"field\":\n",
        "                img = transform_field(img)\n",
        "            elif domain == \"pv\":\n",
        "                if class_id in field_poor_classes and torch.rand(1).item() < 0.5:\n",
        "                    img = transform_pv_field_style(img)\n",
        "                else:\n",
        "                    img = transform_pv_basic(img)\n",
        "            else:\n",
        "                img = transform_pv_field_style(img)\n",
        "        else:\n",
        "            img = transform_eval(img)\n",
        "\n",
        "        return img, class_id\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PlantDataset(all_train_entries, transform_train=True)\n",
        "val_dataset_main = PlantDataset(val_entries_main, transform_train=False)\n",
        "val_dataset_plant_doc = PlantDataset(val_entries_plant_doc, transform_train=False)\n",
        "val_dataset_fieldplant = PlantDataset(val_entries_fieldplant, transform_train=False)\n",
        "\n",
        "print(\"Datasets created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batches: 910\n",
            "Combined validation batches: 97\n",
            "Main validation batches: 97\n",
            "Plant_doc validation batches: 8\n",
            "FieldPlant validation batches: 15\n"
          ]
        }
      ],
      "source": [
        "# Create weighted sampler for training\n",
        "train_class_counts = Counter(e[\"class_id\"] for e in all_train_entries)\n",
        "max_count = max(train_class_counts.values())\n",
        "class_weights = {cid: max_count / cnt for cid, cnt in train_class_counts.items()}\n",
        "sample_weights = [class_weights[e[\"class_id\"]] for e in all_train_entries]\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=torch.DoubleTensor(sample_weights),\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# Optimized batch size for RTX 3070 Super (8GB VRAM)\n",
        "# Can handle larger batches with mixed precision\n",
        "BATCH_SIZE = 64  # Increased from 32\n",
        "\n",
        "# Combined training loader\n",
        "combined_train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "# Combined validation loader (for fine-tuning monitoring)\n",
        "combined_val_loader = DataLoader(\n",
        "    val_dataset_main,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "# Separate validation loaders for evaluation\n",
        "val_loader_main = DataLoader(\n",
        "    val_dataset_main,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader_plant_doc = DataLoader(\n",
        "    val_dataset_plant_doc,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader_fieldplant = DataLoader(\n",
        "    val_dataset_fieldplant,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(combined_train_loader)}\")\n",
        "print(f\"Combined validation batches: {len(combined_val_loader)}\")\n",
        "print(f\"Main validation batches: {len(val_loader_main)}\")\n",
        "print(f\"Plant_doc validation batches: {len(val_loader_plant_doc)}\")\n",
        "print(f\"FieldPlant validation batches: {len(val_loader_fieldplant)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Define Training and Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and evaluation functions defined.\n"
          ]
        }
      ],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None, use_amp=False):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_targets = []\n",
        "    all_preds = []\n",
        "\n",
        "    for images, targets in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if use_amp and scaler is not None:\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_targets.append(targets.detach().cpu())\n",
        "        all_preds.append(preds.detach().cpu())\n",
        "\n",
        "    if len(all_targets) == 0:\n",
        "        raise ValueError(\"Training loader is empty!\")\n",
        "    \n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = (all_targets == all_preds).mean()\n",
        "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device, use_amp=False):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_targets = []\n",
        "    all_preds = []\n",
        "\n",
        "    for images, targets in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if use_amp:\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_targets.append(targets.detach().cpu())\n",
        "        all_preds.append(preds.detach().cpu())\n",
        "\n",
        "    if len(all_targets) == 0:\n",
        "        return 0.0, 0.0, 0.0, np.array([]), np.array([])\n",
        "    \n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset) if len(loader.dataset) > 0 else 0.0\n",
        "    epoch_acc = (all_targets == all_preds).mean() if len(all_targets) > 0 else 0.0\n",
        "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\") if len(all_targets) > 0 else 0.0\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1, all_targets, all_preds\n",
        "\n",
        "print(\"Training and evaluation functions defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Fine-Tuning Function with Lower Learning Rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fine_tune_model(\n",
        "    checkpoint_path,\n",
        "    train_loader_combined,\n",
        "    val_loader_combined,\n",
        "    max_epochs=5,\n",
        "    lr=1e-4,  # Lower learning rate for fine-tuning\n",
        "    weight_decay=1e-4,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        "    use_layerwise_lr=True  # Use different LRs for different layers\n",
        "):\n",
        "    \"\"\"\n",
        "    Fine-tune a pre-trained model on additional datasets.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to pre-trained model checkpoint\n",
        "        train_loader_combined: Combined training DataLoader\n",
        "        val_loader_combined: Combined validation DataLoader (for monitoring)\n",
        "        max_epochs: Maximum number of fine-tuning epochs (default: 5)\n",
        "        lr: Learning rate (default: 1e-4, 10x lower than original)\n",
        "        use_layerwise_lr: If True, use different LRs for different layers\n",
        "    \"\"\"\n",
        "    print(f\"Loading pre-trained model from: {checkpoint_path}\")\n",
        "    \n",
        "    # Load the pre-trained model\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "    model_name = checkpoint[\"model_name\"]\n",
        "    num_classes = checkpoint[\"num_classes\"]\n",
        "    \n",
        "    # Recreate model (use pretrained=True to ensure ImageNet weights if checkpoint fails)\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=True,  # Always use pretrained ImageNet weights\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    model.to(device)\n",
        "    \n",
        "    # Use torch.compile for faster execution (if enabled)\n",
        "    if USE_COMPILE:\n",
        "        print(f\"  -> Compiling model with torch.compile()...\")\n",
        "        model = torch.compile(model, mode='reduce-overhead')\n",
        "        print(f\"  -> Model compiled!\")\n",
        "    \n",
        "    print(f\"Model loaded: {model_name}, num_classes: {num_classes}\")\n",
        "    print(f\"Original best validation F1: {checkpoint.get('best_val_f1', 'N/A'):.4f}\")\n",
        "    \n",
        "    # Create optimizer with layer-wise learning rates\n",
        "    if use_layerwise_lr and hasattr(model, 'blocks'):  # For EfficientNet/ViT\n",
        "        # Different learning rates for different layers\n",
        "        # Early layers: very low LR (frozen-like)\n",
        "        # Middle layers: low LR\n",
        "        # Later layers: normal LR\n",
        "        # Classifier: higher LR\n",
        "        \n",
        "        # Get layer groups (this is model-specific)\n",
        "        if 'efficientnet' in model_name.lower():\n",
        "            # EfficientNet structure\n",
        "            early_params = []\n",
        "            middle_params = []\n",
        "            late_params = []\n",
        "            classifier_params = []\n",
        "            \n",
        "            for name, param in model.named_parameters():\n",
        "                if 'classifier' in name:\n",
        "                    classifier_params.append(param)\n",
        "                elif 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
        "                    early_params.append(param)\n",
        "                elif 'blocks.3' in name or 'blocks.4' in name or 'blocks.5' in name:\n",
        "                    middle_params.append(param)\n",
        "                else:\n",
        "                    late_params.append(param)\n",
        "            \n",
        "            optimizer = AdamW([\n",
        "                {'params': early_params, 'lr': lr * 0.1},      # 10% of base LR\n",
        "                {'params': middle_params, 'lr': lr * 0.5},    # 50% of base LR\n",
        "                {'params': late_params, 'lr': lr},             # 100% of base LR\n",
        "                {'params': classifier_params, 'lr': lr * 2}    # 200% of base LR\n",
        "            ], weight_decay=weight_decay)\n",
        "            \n",
        "            print(\"Using layer-wise learning rates:\")\n",
        "            print(f\"  Early layers: {lr * 0.1:.6f}\")\n",
        "            print(f\"  Middle layers: {lr * 0.5:.6f}\")\n",
        "            print(f\"  Late layers: {lr:.6f}\")\n",
        "            print(f\"  Classifier: {lr * 2:.6f}\")\n",
        "        else:\n",
        "            # For ViT or other models, use simpler grouping\n",
        "            optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            print(f\"Using uniform learning rate: {lr:.6f}\")\n",
        "    else:\n",
        "        # Uniform learning rate\n",
        "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        print(f\"Using uniform learning rate: {lr:.6f}\")\n",
        "    \n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Initialize gradient scaler for mixed precision\n",
        "    scaler = GradScaler('cuda') if USE_AMP else None\n",
        "    if USE_AMP:\n",
        "        print(\"  -> Mixed precision training enabled (FP16)\")\n",
        "    \n",
        "    # Track best model\n",
        "    best_val_f1 = checkpoint.get(\"best_val_f1\", -1.0)\n",
        "    best_state = copy.deepcopy(model.state_dict())\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"train_f1\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"val_f1\": []\n",
        "    }\n",
        "    \n",
        "    epochs_without_improvement = 0\n",
        "    \n",
        "    print(f\"\\nStarting fine-tuning:\")\n",
        "    print(f\"  -> Training samples: {len(train_loader_combined.dataset)}\")\n",
        "    print(f\"  -> Validation samples: {len(val_loader_combined.dataset)}\")\n",
        "    print(f\"  -> Max epochs: {max_epochs}\")\n",
        "    print(f\"  -> Base learning rate: {lr}\")\n",
        "    print(f\"  -> Early stopping patience: {early_stopping_patience}\")\n",
        "    \n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        train_loss, train_acc, train_f1 = train_one_epoch(\n",
        "            model, train_loader_combined, criterion, optimizer, device, scaler, USE_AMP\n",
        "        )\n",
        "        val_loss, val_acc, val_f1, _, _ = evaluate(\n",
        "            model, val_loader_combined, criterion, device, USE_AMP\n",
        "        )\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        print(f\"Fine-tune Epoch {epoch:02d}/{max_epochs} ({elapsed:.1f}s)\")\n",
        "        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
        "        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
        "        \n",
        "        # Track best by validation F1\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            epochs_without_improvement = 0\n",
        "            print(f\"  -> New best! Val F1: {best_val_f1:.4f}\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping_patience:\n",
        "                print(f\"  -> Early stopping after {epoch} epochs\")\n",
        "                break\n",
        "    \n",
        "    # Load best weights\n",
        "    model.load_state_dict(best_state)\n",
        "    \n",
        "    # Save fine-tuned model\n",
        "    ckpt_path = MODELS_DIR / f\"{model_name}_fine_tuned.pt\"\n",
        "    torch.save({\n",
        "        \"model_name\": model_name,\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"num_classes\": num_classes,\n",
        "        \"best_val_f1\": best_val_f1,\n",
        "        \"history\": history,\n",
        "        \"base_checkpoint\": str(checkpoint_path),\n",
        "        \"fine_tuned\": True,\n",
        "        \"fine_tune_epochs\": epoch,\n",
        "        \"fine_tune_lr\": lr\n",
        "    }, ckpt_path)\n",
        "    print(f\"\\nSaved fine-tuned checkpoint to: {ckpt_path}\")\n",
        "    \n",
        "    return model, history, best_val_f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Fine-Tune EfficientNet-B0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FINE-TUNING EFFICIENTNET-B0\n",
            "======================================================================\n",
            "Loading pre-trained model from: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\models\\efficientnet_b0_best.pt\n",
            "Model loaded: efficientnet_b0, num_classes: 39\n",
            "Original best validation F1: 0.9988\n",
            "Using layer-wise learning rates:\n",
            "  Early layers: 0.000010\n",
            "  Middle layers: 0.000050\n",
            "  Late layers: 0.000100\n",
            "  Classifier: 0.000200\n",
            "  -> Mixed precision training enabled (FP16)\n",
            "\n",
            "Starting fine-tuning:\n",
            "  -> Training samples: 58227\n",
            "  -> Validation samples: 6148\n",
            "  -> Max epochs: 5\n",
            "  -> Base learning rate: 0.0001\n",
            "  -> Early stopping patience: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune Epoch 01/5 (557.1s)\n",
            "  Train - Loss: 0.1966, Acc: 0.9455, F1: 0.9456\n",
            "  Val   - Loss: 0.0070, Acc: 0.9982, F1: 0.9976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune Epoch 02/5 (582.1s)\n",
            "  Train - Loss: 0.0817, Acc: 0.9743, F1: 0.9743\n",
            "  Val   - Loss: 0.0107, Acc: 0.9974, F1: 0.9966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune Epoch 03/5 (628.1s)\n",
            "  Train - Loss: 0.0491, Acc: 0.9847, F1: 0.9847\n",
            "  Val   - Loss: 0.0089, Acc: 0.9979, F1: 0.9972\n",
            "  -> Early stopping after 3 epochs\n",
            "\n",
            "Saved fine-tuned checkpoint to: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\models\\efficientnet_b0_fine_tuned.pt\n",
            "\n",
            "Fine-tuning complete!\n",
            "Best validation F1: 0.9988\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune EfficientNet-B0\n",
        "print(\"=\"*70)\n",
        "print(\"FINE-TUNING EFFICIENTNET-B0\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "checkpoint_path_eff = MODELS_DIR / \"efficientnet_b0_best.pt\"\n",
        "\n",
        "model_eff_finetuned, history_eff, best_val_f1_eff = fine_tune_model(\n",
        "    checkpoint_path=checkpoint_path_eff,\n",
        "    train_loader_combined=combined_train_loader,\n",
        "    val_loader_combined=combined_val_loader,\n",
        "    max_epochs=5,\n",
        "    lr=1e-4,  # 10x lower than original 3e-4\n",
        "    weight_decay=1e-4,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        "    use_layerwise_lr=True\n",
        ")\n",
        "\n",
        "print(f\"\\nFine-tuning complete!\")\n",
        "print(f\"Best validation F1: {best_val_f1_eff:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Fine-Tune ViT-Base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FINE-TUNING VIT-BASE\n",
            "======================================================================\n",
            "Loading pre-trained model from: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\models\\vit_base_patch16_224_best.pt\n",
            "Model loaded: vit_base_patch16_224, num_classes: 39\n",
            "Original best validation F1: 0.9711\n",
            "Using uniform learning rate: 0.000100\n",
            "  -> Mixed precision training enabled (FP16)\n",
            "\n",
            "Starting fine-tuning:\n",
            "  -> Training samples: 58227\n",
            "  -> Validation samples: 6148\n",
            "  -> Max epochs: 5\n",
            "  -> Base learning rate: 0.0001\n",
            "  -> Early stopping patience: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune Epoch 01/5 (572.2s)\n",
            "  Train - Loss: 0.6271, Acc: 0.8455, F1: 0.8464\n",
            "  Val   - Loss: 0.1428, Acc: 0.9546, F1: 0.9499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune Epoch 02/5 (454.9s)\n",
            "  Train - Loss: 0.4894, Acc: 0.8591, F1: 0.8598\n",
            "  Val   - Loss: 0.1071, Acc: 0.9636, F1: 0.9606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune Epoch 03/5 (445.2s)\n",
            "  Train - Loss: 0.4239, Acc: 0.8769, F1: 0.8778\n",
            "  Val   - Loss: 0.1056, Acc: 0.9660, F1: 0.9613\n",
            "  -> Early stopping after 3 epochs\n",
            "\n",
            "Saved fine-tuned checkpoint to: d:\\Programming\\Seminar_Project\\PLANT_LEAF_DISEASE_DETECTION\\models\\vit_base_patch16_224_fine_tuned.pt\n",
            "\n",
            "Fine-tuning complete!\n",
            "Best validation F1: 0.9711\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune ViT-Base\n",
        "print(\"=\"*70)\n",
        "print(\"FINE-TUNING VIT-BASE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "checkpoint_path_vit = MODELS_DIR / \"vit_base_patch16_224_best.pt\"\n",
        "\n",
        "model_vit_finetuned, history_vit, best_val_f1_vit = fine_tune_model(\n",
        "    checkpoint_path=checkpoint_path_vit,\n",
        "    train_loader_combined=combined_train_loader,\n",
        "    val_loader_combined=combined_val_loader,\n",
        "    max_epochs=5,\n",
        "    lr=1e-4,  # 10x lower than original 3e-4\n",
        "    weight_decay=1e-4,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        "    use_layerwise_lr=False  # ViT structure is different, use uniform LR\n",
        ")\n",
        "\n",
        "print(f\"\\nFine-tuning complete!\")\n",
        "print(f\"Best validation F1: {best_val_f1_vit:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Evaluate on All Three Validation Sets Separately\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EFFICIENTNET-B0 FINE-TUNED VALIDATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "VALIDATION RESULTS FOR EFFICIENTNET-B0 FINE-TUNED\n",
            "======================================================================\n",
            "\n",
            "Evaluating on MAIN dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss: 0.0068\n",
            "  Accuracy: 0.9990 (99.90%)\n",
            "  Macro F1: 0.9988 (99.88%)\n",
            "  Total samples: 6148\n",
            "\n",
            "Evaluating on PLANT_DOC dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss: 6.4742\n",
            "  Accuracy: 0.2421 (24.21%)\n",
            "  Macro F1: 0.2061 (20.61%)\n",
            "  Total samples: 504\n",
            "\n",
            "Evaluating on FIELDPLANT dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss: 7.9304\n",
            "  Accuracy: 0.1573 (15.73%)\n",
            "  Macro F1: 0.0395 (3.95%)\n",
            "  Total samples: 928\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_on_all_datasets(model, val_loaders_dict, criterion, device, model_name):\n",
        "    \"\"\"Evaluate model on all validation datasets and return detailed statistics.\"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"VALIDATION RESULTS FOR {model_name.upper()}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Specify all class labels explicitly to include all 39 classes\n",
        "    all_class_labels = list(range(num_classes))\n",
        "    \n",
        "    for dataset_name, val_loader in val_loaders_dict.items():\n",
        "        if len(val_loader) == 0:\n",
        "            print(f\"Skipping {dataset_name.upper()} (empty dataset)\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"Evaluating on {dataset_name.upper()} dataset...\")\n",
        "        val_loss, val_acc, val_f1, all_targets, all_preds = evaluate(\n",
        "            model, val_loader, criterion, device, USE_AMP\n",
        "        )\n",
        "        \n",
        "        # Per-class metrics\n",
        "        if len(all_targets) > 0:\n",
        "            class_report = classification_report(\n",
        "                all_targets, all_preds,\n",
        "                labels=all_class_labels, \n",
        "                target_names=[id_to_label[i] for i in range(num_classes)],\n",
        "                output_dict=True,\n",
        "                zero_division=0\n",
        "            )\n",
        "            \n",
        "            # Confusion matrix\n",
        "            cm = confusion_matrix(all_targets, all_preds)\n",
        "            \n",
        "            results[dataset_name] = {\n",
        "                \"loss\": val_loss,\n",
        "                \"accuracy\": val_acc,\n",
        "                \"f1_macro\": val_f1,\n",
        "                \"all_targets\": all_targets,\n",
        "                \"all_preds\": all_preds,\n",
        "                \"classification_report\": class_report,\n",
        "                \"confusion_matrix\": cm\n",
        "            }\n",
        "            \n",
        "            print(f\"  Loss: {val_loss:.4f}\")\n",
        "            print(f\"  Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
        "            print(f\"  Macro F1: {val_f1:.4f} ({val_f1*100:.2f}%)\")\n",
        "            print(f\"  Total samples: {len(all_targets)}\")\n",
        "            print()\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Prepare validation loaders dictionary\n",
        "val_loaders_dict = {\n",
        "    \"main\": val_loader_main,\n",
        "    \"plant_doc\": val_loader_plant_doc,\n",
        "    \"fieldplant\": val_loader_fieldplant\n",
        "}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Evaluate EfficientNet\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EFFICIENTNET-B0 FINE-TUNED VALIDATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "results_eff = evaluate_on_all_datasets(model_eff_finetuned, val_loaders_dict, criterion, DEVICE, \"EfficientNet-B0 Fine-Tuned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VIT-BASE FINE-TUNED VALIDATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "VALIDATION RESULTS FOR VIT-BASE FINE-TUNED\n",
            "======================================================================\n",
            "\n",
            "Evaluating on MAIN dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss: 0.0848\n",
            "  Accuracy: 0.9741 (97.41%)\n",
            "  Macro F1: 0.9710 (97.10%)\n",
            "  Total samples: 6148\n",
            "\n",
            "Evaluating on PLANT_DOC dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss: 9.4252\n",
            "  Accuracy: 0.0516 (5.16%)\n",
            "  Macro F1: 0.0381 (3.81%)\n",
            "  Total samples: 504\n",
            "\n",
            "Evaluating on FIELDPLANT dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kero\\AppData\\Local\\Temp\\ipykernel_29648\\1841790277.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss: 6.2760\n",
            "  Accuracy: 0.1746 (17.46%)\n",
            "  Macro F1: 0.0268 (2.68%)\n",
            "  Total samples: 928\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate ViT\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VIT-BASE FINE-TUNED VALIDATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "results_vit = evaluate_on_all_datasets(model_vit_finetuned, val_loaders_dict, criterion, DEVICE, \"ViT-Base Fine-Tuned\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Summary Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "SUMMARY COMPARISON TABLE\n",
            "======================================================================\n",
            "\n",
            "Performance across all validation datasets:\n",
            "\n",
            "   Dataset                        Model  Accuracy  F1 Macro     Loss  Samples\n",
            "      MAIN EfficientNet-B0 (Fine-Tuned)  0.999024  0.998801 0.006806     6148\n",
            "      MAIN        ViT-Base (Fine-Tuned)  0.974138  0.971001 0.084781     6148\n",
            " PLANT_DOC EfficientNet-B0 (Fine-Tuned)  0.242063  0.206061 6.474166      504\n",
            " PLANT_DOC        ViT-Base (Fine-Tuned)  0.051587  0.038147 9.425156      504\n",
            "FIELDPLANT EfficientNet-B0 (Fine-Tuned)  0.157328  0.039494 7.930360      928\n",
            "FIELDPLANT        ViT-Base (Fine-Tuned)  0.174569  0.026753 6.276009      928\n",
            "\n",
            "======================================================================\n",
            "OVERALL STATISTICS\n",
            "======================================================================\n",
            "\n",
            "EfficientNet-B0 (Fine-Tuned):\n",
            "  Average Accuracy across datasets: 0.4661\n",
            "  Average F1 Macro across datasets: 0.4148\n",
            "\n",
            "ViT-Base (Fine-Tuned):\n",
            "  Average Accuracy across datasets: 0.4001\n",
            "  Average F1 Macro across datasets: 0.3453\n",
            "\n",
            "======================================================================\n",
            "BEST MODEL PER DATASET\n",
            "======================================================================\n",
            "MAIN: EfficientNet-B0 (F1: 0.9988)\n",
            "PLANT_DOC: EfficientNet-B0 (F1: 0.2061)\n",
            "FIELDPLANT: EfficientNet-B0 (F1: 0.0395)\n"
          ]
        }
      ],
      "source": [
        "# Create summary comparison table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY COMPARISON TABLE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nPerformance across all validation datasets:\\n\")\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_data = []\n",
        "for dataset_name in [\"main\", \"plant_doc\", \"fieldplant\"]:\n",
        "    if dataset_name in results_eff and dataset_name in results_vit:\n",
        "        comparison_data.append({\n",
        "            \"Dataset\": dataset_name.upper(),\n",
        "            \"Model\": \"EfficientNet-B0 (Fine-Tuned)\",\n",
        "            \"Accuracy\": results_eff[dataset_name][\"accuracy\"],\n",
        "            \"F1 Macro\": results_eff[dataset_name][\"f1_macro\"],\n",
        "            \"Loss\": results_eff[dataset_name][\"loss\"],\n",
        "            \"Samples\": len(results_eff[dataset_name][\"all_targets\"])\n",
        "        })\n",
        "        comparison_data.append({\n",
        "            \"Dataset\": dataset_name.upper(),\n",
        "            \"Model\": \"ViT-Base (Fine-Tuned)\",\n",
        "            \"Accuracy\": results_vit[dataset_name][\"accuracy\"],\n",
        "            \"F1 Macro\": results_vit[dataset_name][\"f1_macro\"],\n",
        "            \"Loss\": results_vit[dataset_name][\"loss\"],\n",
        "            \"Samples\": len(results_vit[dataset_name][\"all_targets\"])\n",
        "        })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# Overall statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nEfficientNet-B0 (Fine-Tuned):\")\n",
        "eff_df = df_comparison[df_comparison['Model']=='EfficientNet-B0 (Fine-Tuned)']\n",
        "if len(eff_df) > 0:\n",
        "    print(f\"  Average Accuracy across datasets: {eff_df['Accuracy'].mean():.4f}\")\n",
        "    print(f\"  Average F1 Macro across datasets: {eff_df['F1 Macro'].mean():.4f}\")\n",
        "\n",
        "print(\"\\nViT-Base (Fine-Tuned):\")\n",
        "vit_df = df_comparison[df_comparison['Model']=='ViT-Base (Fine-Tuned)']\n",
        "if len(vit_df) > 0:\n",
        "    print(f\"  Average Accuracy across datasets: {vit_df['Accuracy'].mean():.4f}\")\n",
        "    print(f\"  Average F1 Macro across datasets: {vit_df['F1 Macro'].mean():.4f}\")\n",
        "\n",
        "# Best model per dataset\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEST MODEL PER DATASET\")\n",
        "print(\"=\"*70)\n",
        "for dataset_name in [\"main\", \"plant_doc\", \"fieldplant\"]:\n",
        "    if dataset_name in results_eff and dataset_name in results_vit:\n",
        "        eff_f1 = results_eff[dataset_name][\"f1_macro\"]\n",
        "        vit_f1 = results_vit[dataset_name][\"f1_macro\"]\n",
        "        best_model = \"EfficientNet-B0\" if eff_f1 > vit_f1 else \"ViT-Base\"\n",
        "        print(f\"{dataset_name.upper()}: {best_model} (F1: {max(eff_f1, vit_f1):.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Visual Inspection of Misclassified Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUAL INSPECTION OF MISCLASSIFIED IMAGES\n",
            "======================================================================\n",
            "\n",
            "Analyzing Plant_doc misclassifications...\n",
            "\n",
            "======================================================================\n",
            "VISUAL INSPECTION: PLANT_DOC\n",
            "======================================================================\n",
            "Total misclassifications: 382\n",
            "Sampling 30 examples\n",
            "\n",
            "âœ“ Saved grid visualization: misclassification_analysis\\plant_doc\\misclassification_grid_plant_doc.png\n",
            "\n",
            "======================================================================\n",
            "MISCLASSIFICATION SUMMARY: PLANT_DOC\n",
            "======================================================================\n",
            "\n",
            "Misclassifications by True Class (Top 10):\n",
            "  potato_early_blight: 24 misclassifications\n",
            "  tomato_septoria_leaf_spot: 24 misclassifications\n",
            "  apple_cedar_apple_rust: 20 misclassifications\n",
            "  tomato_tomato_mosaic_virus: 20 misclassifications\n",
            "  tomato_bacterial_spot: 18 misclassifications\n",
            "  apple_apple_scab: 16 misclassifications\n",
            "  corn_northern_leaf_blight: 16 misclassifications\n",
            "  soybean_healthy: 16 misclassifications\n",
            "  strawberry_healthy: 16 misclassifications\n",
            "  tomato_healthy: 16 misclassifications\n",
            "\n",
            "Most Common Incorrect Predictions (Top 10):\n",
            "  background_without_leaves: predicted 158 times (incorrectly)\n",
            "  tomato_late_blight: predicted 30 times (incorrectly)\n",
            "  tomato_tomato_yellow_leaf_curl_virus: predicted 26 times (incorrectly)\n",
            "  corn_cercospora_leaf_spot_gray_leaf_spot: predicted 24 times (incorrectly)\n",
            "  cherry_healthy: predicted 16 times (incorrectly)\n",
            "  strawberry_leaf_scorch: predicted 16 times (incorrectly)\n",
            "  apple_healthy: predicted 12 times (incorrectly)\n",
            "  corn_healthy: predicted 12 times (incorrectly)\n",
            "  grape_healthy: predicted 10 times (incorrectly)\n",
            "  blueberry_healthy: predicted 8 times (incorrectly)\n",
            "\n",
            "âœ“ Individual images saved to: misclassification_analysis\\plant_doc\n",
            "âœ“ Total images saved: 30\n",
            "\n",
            "Analyzing FieldPlant misclassifications...\n",
            "\n",
            "======================================================================\n",
            "VISUAL INSPECTION: FIELDPLANT\n",
            "======================================================================\n",
            "Total misclassifications: 782\n",
            "Sampling 30 examples\n",
            "\n",
            "âœ“ Saved grid visualization: misclassification_analysis\\fieldplant\\misclassification_grid_fieldplant.png\n",
            "\n",
            "======================================================================\n",
            "MISCLASSIFICATION SUMMARY: FIELDPLANT\n",
            "======================================================================\n",
            "\n",
            "Misclassifications by True Class (Top 10):\n",
            "  corn_northern_leaf_blight: 582 misclassifications\n",
            "  tomato_healthy: 105 misclassifications\n",
            "  tomato_tomato_yellow_leaf_curl_virus: 38 misclassifications\n",
            "  corn_cercospora_leaf_spot_gray_leaf_spot: 24 misclassifications\n",
            "  corn_common_rust: 21 misclassifications\n",
            "  tomato_tomato_mosaic_virus: 9 misclassifications\n",
            "  corn_healthy: 3 misclassifications\n",
            "\n",
            "Most Common Incorrect Predictions (Top 10):\n",
            "  corn_healthy: predicted 471 times (incorrectly)\n",
            "  background_without_leaves: predicted 146 times (incorrectly)\n",
            "  tomato_late_blight: predicted 45 times (incorrectly)\n",
            "  cherry_healthy: predicted 28 times (incorrectly)\n",
            "  corn_cercospora_leaf_spot_gray_leaf_spot: predicted 15 times (incorrectly)\n",
            "  tomato_early_blight: predicted 14 times (incorrectly)\n",
            "  squash_powdery_mildew: predicted 13 times (incorrectly)\n",
            "  pepper,_bell_healthy: predicted 10 times (incorrectly)\n",
            "  peach_bacterial_spot: predicted 6 times (incorrectly)\n",
            "  orange_haunglongbing_citrus_greening: predicted 6 times (incorrectly)\n",
            "\n",
            "âœ“ Individual images saved to: misclassification_analysis\\fieldplant\n",
            "âœ“ Total images saved: 30\n",
            "\n",
            "======================================================================\n",
            "VISUAL INSPECTION COMPLETE\n",
            "======================================================================\n",
            "\n",
            "Next steps:\n",
            "1. Review the saved images in ./misclassification_analysis/\n",
            "2. Look for patterns in misclassifications:\n",
            "   - Lighting conditions\n",
            "   - Background differences\n",
            "   - Image quality/artifacts\n",
            "   - Similar-looking classes\n",
            "3. Use insights to improve data augmentation and training strategy\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from pathlib import Path\n",
        "\n",
        "def visualize_misclassifications(\n",
        "    model, \n",
        "    val_loader, \n",
        "    results_dict, \n",
        "    dataset_name, \n",
        "    id_to_label,\n",
        "    num_samples=30,\n",
        "    save_dir=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize misclassified images to identify failure patterns.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        val_loader: Validation DataLoader\n",
        "        results_dict: Dictionary containing evaluation results\n",
        "        dataset_name: Name of the dataset ('plant_doc' or 'fieldplant')\n",
        "        id_to_label: Mapping from class ID to label name\n",
        "        num_samples: Number of misclassified samples to visualize\n",
        "        save_dir: Directory to save images (if None, creates 'misclassification_analysis')\n",
        "    \"\"\"\n",
        "    if dataset_name not in results_dict:\n",
        "        print(f\"No results found for {dataset_name}\")\n",
        "        return\n",
        "    \n",
        "    results = results_dict[dataset_name]\n",
        "    targets = results['all_targets']\n",
        "    preds = results['all_preds']\n",
        "    \n",
        "    # Find misclassified samples\n",
        "    misclassified_indices = []\n",
        "    misclassified_info = []\n",
        "    \n",
        "    # Get all entries from the dataset\n",
        "    dataset_entries = []\n",
        "    if dataset_name == \"plant_doc\":\n",
        "        dataset_entries = val_entries_plant_doc\n",
        "    elif dataset_name == \"fieldplant\":\n",
        "        dataset_entries = val_entries_fieldplant\n",
        "    else:\n",
        "        print(f\"Unknown dataset: {dataset_name}\")\n",
        "        return\n",
        "    \n",
        "    for idx, (true_label, pred_label) in enumerate(zip(targets, preds)):\n",
        "        if true_label != pred_label:\n",
        "            misclassified_indices.append(idx)\n",
        "            misclassified_info.append({\n",
        "                'index': idx,\n",
        "                'true_label': true_label,\n",
        "                'pred_label': pred_label,\n",
        "                'true_name': id_to_label[true_label],\n",
        "                'pred_name': id_to_label[pred_label],\n",
        "                'entry': dataset_entries[idx] if idx < len(dataset_entries) else None\n",
        "            })\n",
        "    \n",
        "    if len(misclassified_indices) == 0:\n",
        "        print(f\"No misclassifications found for {dataset_name}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"VISUAL INSPECTION: {dataset_name.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total misclassifications: {len(misclassified_indices)}\")\n",
        "    print(f\"Sampling {min(num_samples, len(misclassified_indices))} examples\\n\")\n",
        "    \n",
        "    # Sample misclassified images\n",
        "    import random\n",
        "    random.seed(42)\n",
        "    sampled_indices = random.sample(\n",
        "        misclassified_indices, \n",
        "        min(num_samples, len(misclassified_indices))\n",
        "    )\n",
        "    \n",
        "    # Create save directory\n",
        "    if save_dir is None:\n",
        "        save_dir = Path(\"./misclassification_analysis\") / dataset_name\n",
        "    else:\n",
        "        save_dir = Path(save_dir) / dataset_name\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Load and visualize images\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    # Create figure for grid display\n",
        "    num_cols = 5\n",
        "    num_rows = (len(sampled_indices) + num_cols - 1) // num_cols\n",
        "    fig = plt.figure(figsize=(20, 4 * num_rows))\n",
        "    gs = gridspec.GridSpec(num_rows, num_cols, figure=fig, hspace=0.4, wspace=0.3)\n",
        "    \n",
        "    for plot_idx, mis_idx in enumerate(sampled_indices):\n",
        "        row = plot_idx // num_cols\n",
        "        col = plot_idx % num_cols\n",
        "        ax = fig.add_subplot(gs[row, col])\n",
        "        \n",
        "        # Get the entry\n",
        "        if mis_idx < len(dataset_entries):\n",
        "            entry = dataset_entries[mis_idx]\n",
        "            img_path = Path(entry['path'])\n",
        "            \n",
        "            try:\n",
        "                # Load and display image\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                ax.imshow(img)\n",
        "                \n",
        "                # Get true and predicted labels\n",
        "                true_label = targets[mis_idx]\n",
        "                pred_label = preds[mis_idx]\n",
        "                true_name = id_to_label[true_label]\n",
        "                pred_name = id_to_label[pred_label]\n",
        "                \n",
        "                # Format labels (truncate if too long)\n",
        "                true_display = true_name[:25] + \"...\" if len(true_name) > 25 else true_name\n",
        "                pred_display = pred_name[:25] + \"...\" if len(pred_name) > 25 else pred_name\n",
        "                \n",
        "                # Set title with color coding\n",
        "                ax.set_title(\n",
        "                    f\"True: {true_display}\\nPred: {pred_display}\",\n",
        "                    fontsize=9,\n",
        "                    color='red' if true_label != pred_label else 'green',\n",
        "                    fontweight='bold'\n",
        "                )\n",
        "                ax.axis('off')\n",
        "                \n",
        "                # Save individual image\n",
        "                save_path = save_dir / f\"misclass_{mis_idx:04d}_true_{true_label}_pred_{pred_label}.jpg\"\n",
        "                img.save(save_path, quality=95)\n",
        "                \n",
        "            except Exception as e:\n",
        "                ax.text(0.5, 0.5, f\"Error loading\\nimage {mis_idx}:\\n{str(e)}\", \n",
        "                       ha='center', va='center', fontsize=8, color='red')\n",
        "                ax.axis('off')\n",
        "                print(f\"Warning: Could not load image {mis_idx}: {e}\")\n",
        "    \n",
        "    # Save grid figure\n",
        "    plt.suptitle(\n",
        "        f\"Misclassified Images: {dataset_name.upper()} Dataset\\n\"\n",
        "        f\"Showing {len(sampled_indices)} of {len(misclassified_indices)} misclassifications\",\n",
        "        fontsize=14, fontweight='bold', y=0.995\n",
        "    )\n",
        "    grid_save_path = save_dir / f\"misclassification_grid_{dataset_name}.png\"\n",
        "    plt.savefig(grid_save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"âœ“ Saved grid visualization: {grid_save_path}\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Create summary statistics\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"MISCLASSIFICATION SUMMARY: {dataset_name.upper()}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    # Count misclassifications by true class\n",
        "    misclass_by_true = {}\n",
        "    for mis_idx in misclassified_indices:\n",
        "        true_label = targets[mis_idx]\n",
        "        true_name = id_to_label[true_label]\n",
        "        if true_name not in misclass_by_true:\n",
        "            misclass_by_true[true_name] = 0\n",
        "        misclass_by_true[true_name] += 1\n",
        "    \n",
        "    print(\"Misclassifications by True Class (Top 10):\")\n",
        "    sorted_misclass = sorted(misclass_by_true.items(), key=lambda x: x[1], reverse=True)\n",
        "    for class_name, count in sorted_misclass[:10]:\n",
        "        print(f\"  {class_name}: {count} misclassifications\")\n",
        "    \n",
        "    # Count misclassifications by predicted class\n",
        "    misclass_by_pred = {}\n",
        "    for mis_idx in misclassified_indices:\n",
        "        pred_label = preds[mis_idx]\n",
        "        pred_name = id_to_label[pred_label]\n",
        "        if pred_name not in misclass_by_pred:\n",
        "            misclass_by_pred[pred_name] = 0\n",
        "        misclass_by_pred[pred_name] += 1\n",
        "    \n",
        "    print(\"\\nMost Common Incorrect Predictions (Top 10):\")\n",
        "    sorted_pred = sorted(misclass_by_pred.items(), key=lambda x: x[1], reverse=True)\n",
        "    for class_name, count in sorted_pred[:10]:\n",
        "        print(f\"  {class_name}: predicted {count} times (incorrectly)\")\n",
        "    \n",
        "    print(f\"\\nâœ“ Individual images saved to: {save_dir}\")\n",
        "    print(f\"âœ“ Total images saved: {len(sampled_indices)}\")\n",
        "    \n",
        "    return save_dir\n",
        "\n",
        "# Visualize misclassifications for both datasets\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VISUAL INSPECTION OF MISCLASSIFIED IMAGES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Visualize Plant_doc misclassifications\n",
        "if \"plant_doc\" in results_eff:\n",
        "    print(\"\\nAnalyzing Plant_doc misclassifications...\")\n",
        "    plant_doc_save_dir = visualize_misclassifications(\n",
        "        model=model_eff_finetuned,\n",
        "        val_loader=val_loader_plant_doc,\n",
        "        results_dict=results_eff,\n",
        "        dataset_name=\"plant_doc\",\n",
        "        id_to_label=id_to_label,\n",
        "        num_samples=30,\n",
        "        save_dir=\"./misclassification_analysis\"\n",
        "    )\n",
        "\n",
        "# Visualize FieldPlant misclassifications\n",
        "if \"fieldplant\" in results_eff:\n",
        "    print(\"\\nAnalyzing FieldPlant misclassifications...\")\n",
        "    fieldplant_save_dir = visualize_misclassifications(\n",
        "        model=model_eff_finetuned,\n",
        "        val_loader=val_loader_fieldplant,\n",
        "        results_dict=results_eff,\n",
        "        dataset_name=\"fieldplant\",\n",
        "        id_to_label=id_to_label,\n",
        "        num_samples=30,\n",
        "        save_dir=\"./misclassification_analysis\"\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VISUAL INSPECTION COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Review the saved images in ./misclassification_analysis/\")\n",
        "print(\"2. Look for patterns in misclassifications:\")\n",
        "print(\"   - Lighting conditions\")\n",
        "print(\"   - Background differences\")\n",
        "print(\"   - Image quality/artifacts\")\n",
        "print(\"   - Similar-looking classes\")\n",
        "print(\"3. Use insights to improve data augmentation and training strategy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "FAILURE ANALYSIS: PLANT_DOC\n",
            "======================================================================\n",
            "\n",
            "Per-Class Accuracy:\n",
            "  Class 0 (apple_apple_scab): 0.200\n",
            "  Class 2 (apple_cedar_apple_rust): 0.000\n",
            "  Class 3 (apple_healthy): 0.222\n",
            "  Class 5 (blueberry_healthy): 0.364\n",
            "  Class 6 (cherry_healthy): 0.300\n",
            "  Class 7 (cherry_powdery_mildew): 0.500\n",
            "  Class 8 (corn_cercospora_leaf_spot_gray_leaf_spot): 0.300\n",
            "  Class 10 (corn_healthy): 0.333\n",
            "  Class 11 (corn_northern_leaf_blight): 0.250\n",
            "  Class 13 (grape_esca_black_measles): 0.667\n",
            "  Class 16 (orange_haunglongbing_citrus_greening): 0.222\n",
            "  Class 17 (peach_bacterial_spot): 0.333\n",
            "  Class 18 (peach_healthy): 0.625\n",
            "  Class 19 (pepper,_bell_bacterial_spot): 0.143\n",
            "  Class 20 (pepper,_bell_healthy): 0.125\n",
            "  Class 21 (potato_early_blight): 0.429\n",
            "  Class 22 (potato_healthy): 0.000\n",
            "  Class 23 (potato_late_blight): 0.333\n",
            "  Class 24 (raspberry_healthy): 0.000\n",
            "  Class 26 (squash_powdery_mildew): 0.000\n",
            "  Class 27 (strawberry_healthy): 0.222\n",
            "  Class 28 (strawberry_leaf_scorch): 0.000\n",
            "  Class 29 (tomato_bacterial_spot): 0.400\n",
            "  Class 30 (tomato_early_blight): 0.000\n",
            "  Class 31 (tomato_healthy): 0.000\n",
            "  Class 32 (tomato_late_blight): 0.000\n",
            "  Class 33 (tomato_leaf_mold): 0.467\n",
            "\n",
            "Top 10 Misclassifications:\n",
            "  strawberry_healthy â†’ background_without_leaves: 14 times\n",
            "  tomato_healthy â†’ background_without_leaves: 14 times\n",
            "  tomato_late_blight â†’ background_without_leaves: 14 times\n",
            "  tomato_leaf_mold â†’ background_without_leaves: 14 times\n",
            "  corn_healthy â†’ cherry_powdery_mildew: 12 times\n",
            "  strawberry_leaf_scorch â†’ background_without_leaves: 12 times\n",
            "  tomato_bacterial_spot â†’ background_without_leaves: 12 times\n",
            "  pepper,_bell_healthy â†’ tomato_bacterial_spot: 10 times\n",
            "  apple_cedar_apple_rust â†’ background_without_leaves: 8 times\n",
            "  apple_healthy â†’ cherry_healthy: 8 times\n",
            "\n",
            "======================================================================\n",
            "FAILURE ANALYSIS: FIELDPLANT\n",
            "======================================================================\n",
            "\n",
            "Per-Class Accuracy:\n",
            "  Class 3 (apple_healthy): 0.040\n",
            "  Class 4 (background_without_leaves): 0.087\n",
            "  Class 5 (blueberry_healthy): 0.957\n",
            "  Class 6 (cherry_healthy): 0.107\n",
            "  Class 16 (orange_haunglongbing_citrus_greening): 0.009\n",
            "  Class 19 (pepper,_bell_bacterial_spot): 0.000\n",
            "  Class 20 (pepper,_bell_healthy): 0.116\n",
            "\n",
            "Top 10 Misclassifications:\n",
            "  cherry_healthy â†’ blueberry_healthy: 434 times\n",
            "  cherry_healthy â†’ apple_apple_scab: 99 times\n",
            "  orange_haunglongbing_citrus_greening â†’ peach_bacterial_spot: 31 times\n",
            "  cherry_healthy â†’ apple_black_rot: 21 times\n",
            "  orange_haunglongbing_citrus_greening â†’ blueberry_healthy: 19 times\n",
            "  pepper,_bell_healthy â†’ apple_apple_scab: 18 times\n",
            "  apple_healthy â†’ blueberry_healthy: 15 times\n",
            "  orange_haunglongbing_citrus_greening â†’ grape_esca_black_measles: 13 times\n",
            "  orange_haunglongbing_citrus_greening â†’ grape_leaf_blight_isariopsis_leaf_spot: 13 times\n",
            "  cherry_healthy â†’ apple_healthy: 10 times\n"
          ]
        }
      ],
      "source": [
        "def analyze_failures(results_dict, dataset_name, id_to_label):\n",
        "    \"\"\"Analyze failure patterns.\"\"\"\n",
        "    if dataset_name not in results_dict:\n",
        "        return\n",
        "    \n",
        "    results = results_dict[dataset_name]\n",
        "    cm = results['confusion_matrix']\n",
        "    targets = results['all_targets']\n",
        "    preds = results['all_preds']\n",
        "    \n",
        "    # Find most confused classes\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"FAILURE ANALYSIS: {dataset_name.upper()}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    # Per-class accuracy\n",
        "    print(\"Per-Class Accuracy:\")\n",
        "    for class_id in range(len(cm)):\n",
        "        if cm[class_id].sum() > 0:\n",
        "            acc = cm[class_id, class_id] / cm[class_id].sum()\n",
        "            print(f\"  Class {class_id} ({id_to_label[class_id]}): {acc:.3f}\")\n",
        "    \n",
        "    # Most common misclassifications\n",
        "    print(\"\\nTop 10 Misclassifications:\")\n",
        "    misclass_pairs = []\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            if i != j and cm[i, j] > 0:\n",
        "                misclass_pairs.append((i, j, cm[i, j]))\n",
        "    misclass_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "    for i, j, count in misclass_pairs[:10]:\n",
        "        print(f\"  {id_to_label[i]} â†’ {id_to_label[j]}: {count} times\")\n",
        "\n",
        "# Run analysis\n",
        "analyze_failures(results_eff, \"plant_doc\", id_to_label)\n",
        "analyze_failures(results_eff, \"fieldplant\", id_to_label)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
